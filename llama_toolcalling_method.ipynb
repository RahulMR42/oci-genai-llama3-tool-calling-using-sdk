{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8aaa69cf",
   "metadata": {},
   "source": [
    "Demo of llama3 tool calling using OCI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4969c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import oci\n",
    "def _init_oci_clients(profile_name):\n",
    "    config = oci.config.from_file(profile_name=profile_name)\n",
    "    generative_ai_inference_client = oci.generative_ai_inference.GenerativeAiInferenceClient(config)\n",
    "    generative_ai_client = oci.generative_ai.GenerativeAiClient(config)\n",
    "    return generative_ai_inference_client,generative_ai_client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4e03925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_user_message(prompt):\n",
    "    command = oci.generative_ai_inference.models.SystemMessage()\n",
    "    command.content = [\n",
    "        oci.generative_ai_inference.models.TextContent(\n",
    "            text = \"Please, follow the next instructions: \\n\" \\\n",
    "            \"You are a helpful assistant that answers questions from sales administrator \\n \" \\\n",
    "            \"about the sales reps.Use the provided tools to search for data about the sales rep. \\n \" \\\n",
    "            \"When searching, be persistent. If a tool result is not sufficient, suggest revised tool \\n \" \\\n",
    "            \"parameters or another tool call.\"\n",
    "        )\n",
    "    ]\n",
    "    # Step 1, call model with function definitions\n",
    "    content = oci.generative_ai_inference.models.TextContent(\n",
    "        text = prompt\n",
    "    )\n",
    "\n",
    "    user_message = oci.generative_ai_inference.models.UserMessage()\n",
    "    user_message.content = [content]\n",
    "    return user_message,command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d9364dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual function behind sales_search to return data.\n",
    "def _function_sales_search():\n",
    "    \"\"\"\"Actual login behind the search \"\"\"\n",
    "    return '\"{\\\"sales_data\\\": \\\"1,000$\\\", \\\"firstName\\\": \\\"John\\\", \\\"month\\\": \\\"Jan\\\", \\\"year\\\": 2020}\"'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fef80c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tool function defenition\n",
    "sales_search = oci.generative_ai_inference.models.FunctionDefinition(\n",
    "    name=\"sales_search\",\n",
    "    description=\"Allows to search for sales rep data.\",\n",
    "    parameters = {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"firstName\": {\n",
    "                \"type\": \"string\",\n",
    "            },\n",
    "            \"description\": \"FirstName of the sales rep.\"\n",
    "        },\n",
    "        \"required\": [ \"firstName\" ]\n",
    "\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41806e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_chat_params(command,user_message,mode,\n",
    "                    tool_call_message:str=None,\n",
    "                    tool_message:str=None,):\n",
    "    chat_request = oci.generative_ai_inference.models.GenericChatRequest()\n",
    "    chat_request.api_format = oci.generative_ai_inference.models.BaseChatRequest.API_FORMAT_GENERIC\n",
    "    chat_request.temperature = 0\n",
    "    chat_request.is_stream = False\n",
    "    if mode == \"set\":\n",
    "        chat_request.messages = [command, user_message]\n",
    "        chat_request.tool_choice = oci.generative_ai_inference.models.ToolChoiceAuto()\n",
    "        chat_request.tools = [ sales_search ]\n",
    "    elif mode == \"run\":\n",
    "        chat_request.messages = [command, user_message, tool_call_message, tool_message] \n",
    "    return chat_request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cc81704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_oci_genai_chat_details(model_id,compartment_id,chat_request_details):\n",
    "    chat_detail = oci.generative_ai_inference.models.ChatDetails()\n",
    "    # Here to update to use desired model_id, more instruction in above TODO 2\n",
    "    chat_detail.serving_mode = oci.generative_ai_inference.models.OnDemandServingMode(model_id=model_id)\n",
    "    # chat_detail.serving_mode = oci.generative_ai_inference.models.DedicatedServingMode(endpoint_id=\"<your-endpoint-id>\")\n",
    "    chat_detail.compartment_id = compartment_id\n",
    "    chat_detail.chat_request = chat_request_details\n",
    "    return chat_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a1aad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_chat_using_oci_geneai(oci_genai_chat_details,generative_ai_inference_client,message,verbose:bool=False):\n",
    "    chat_response = generative_ai_inference_client.chat(oci_genai_chat_details)\n",
    "    print(f\"------------{message}---------------\")\n",
    "    if verbose == True:\n",
    "        print(vars(chat_response))\n",
    "    return chat_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bdbcd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_function_results_for_tool_executions(chat_response):\n",
    "    #Step2 parse the tool function results back to model for final output\n",
    "    tool_call_message = chat_response.data.chat_response.choices[0].message\n",
    "    # TODO allow None content for tool call message\n",
    "    tool_call_message.content = [oci.generative_ai_inference.models.TextContent(text=\"\")]\n",
    "    text = _function_sales_search()\n",
    "    tool_content = oci.generative_ai_inference.models.TextContent(text = text )\n",
    "\n",
    "    tool_message = oci.generative_ai_inference.models.ToolMessage(\n",
    "        content = [ tool_content ],\n",
    "        tool_call_id = tool_call_message.tool_calls[0].id\n",
    "    )\n",
    "    return tool_call_message, tool_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9625004",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Variables\n",
    "COMPARTMENT_ID = \"OCI Of the Compartment\"\n",
    "AUTH_TYPE = \"API_KEY\" # The authentication type to use, e.g., API_KEY (default), SECURITY_TOKEN, INSTANCE_PRINCIPAL, RESOURCE_PRINCIPAL.\n",
    "CONFIG_PROFILE = \"OCI PROFILE\"\n",
    "MODEL_ID=\"meta.llama-3.3-70b-instruct\"\n",
    "QUESTIONS=[\"What is the sales made by John for Jan 2020?\",\"What is the total sales by Alex\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d61da94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Disable proxy (Optional)\n",
    "import os\n",
    "os.environ['no_proxy'] = '*' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2dd5900e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❓Ask 1: -> What is the sales made by John for Jan 2020?\n",
      "------------❶ Step-1 set tool---------------\n",
      "------------❷ Step-2 run tool---------------\n",
      "{'status': 200, 'headers': {'content-type': 'application/json', 'opc-request-id': '5126EDF9701D466FB10112678FE12489/04CF875A20F2FAF4E7C9F8FD6A17D385/491DA8D9DE53BA57B08E3679BD27C4AF', 'content-encoding': 'gzip', 'content-length': '315'}, 'data': {\n",
      "  \"chat_response\": {\n",
      "    \"api_format\": \"GENERIC\",\n",
      "    \"choices\": [\n",
      "      {\n",
      "        \"finish_reason\": \"stop\",\n",
      "        \"index\": 0,\n",
      "        \"logprobs\": {\n",
      "          \"text_offset\": null,\n",
      "          \"token_logprobs\": null,\n",
      "          \"tokens\": null,\n",
      "          \"top_logprobs\": null\n",
      "        },\n",
      "        \"message\": {\n",
      "          \"content\": [\n",
      "            {\n",
      "              \"text\": \"The sales made by John for Jan 2020 is $1,000.\",\n",
      "              \"type\": \"TEXT\"\n",
      "            }\n",
      "          ],\n",
      "          \"name\": null,\n",
      "          \"role\": \"ASSISTANT\",\n",
      "          \"tool_calls\": []\n",
      "        }\n",
      "      }\n",
      "    ],\n",
      "    \"time_created\": \"2025-04-25T13:12:57.566000+00:00\"\n",
      "  },\n",
      "  \"model_id\": \"meta.llama-3.3-70b-instruct\",\n",
      "  \"model_version\": \"1.0.0\"\n",
      "}, 'request': <oci.request.Request object at 0x124e55130>, 'next_page': None, 'request_id': '5126EDF9701D466FB10112678FE12489/04CF875A20F2FAF4E7C9F8FD6A17D385/491DA8D9DE53BA57B08E3679BD27C4AF'}\n",
      "❓Ask 2: -> What is the total sales by Alex\n",
      "------------❶ Step-1 set tool---------------\n",
      "------------❷ Step-2 run tool---------------\n",
      "{'status': 200, 'headers': {'content-type': 'application/json', 'opc-request-id': '0A30FE7354C34F73B36627C11D2AD72B/921E9AC5EB86ED9040558CA6F60932B0/A718CDDFEF8BA03EEA5CD40F3E5BF002', 'content-encoding': 'gzip', 'content-length': '407'}, 'data': {\n",
      "  \"chat_response\": {\n",
      "    \"api_format\": \"GENERIC\",\n",
      "    \"choices\": [\n",
      "      {\n",
      "        \"finish_reason\": \"stop\",\n",
      "        \"index\": 0,\n",
      "        \"logprobs\": {\n",
      "          \"text_offset\": null,\n",
      "          \"token_logprobs\": null,\n",
      "          \"tokens\": null,\n",
      "          \"top_logprobs\": null\n",
      "        },\n",
      "        \"message\": {\n",
      "          \"content\": [\n",
      "            {\n",
      "              \"text\": \"The search results only show sales data for John, not Alex. Let me try again with a different approach.\\n\\n{\\\"name\\\": \\\"sales_search\\\", \\\"parameters\\\": {\\\"firstName\\\": \\\"Alex\\\", \\\"month\\\": \\\"all\\\", \\\"year\\\": \\\"all\\\"}}\",\n",
      "              \"type\": \"TEXT\"\n",
      "            }\n",
      "          ],\n",
      "          \"name\": null,\n",
      "          \"role\": \"ASSISTANT\",\n",
      "          \"tool_calls\": []\n",
      "        }\n",
      "      }\n",
      "    ],\n",
      "    \"time_created\": \"2025-04-25T13:13:00.446000+00:00\"\n",
      "  },\n",
      "  \"model_id\": \"meta.llama-3.3-70b-instruct\",\n",
      "  \"model_version\": \"1.0.0\"\n",
      "}, 'request': <oci.request.Request object at 0x124e56090>, 'next_page': None, 'request_id': '0A30FE7354C34F73B36627C11D2AD72B/921E9AC5EB86ED9040558CA6F60932B0/A718CDDFEF8BA03EEA5CD40F3E5BF002'}\n"
     ]
    }
   ],
   "source": [
    "generative_ai_inference_client,generative_ai_client = _init_oci_clients(profile_name=CONFIG_PROFILE)\n",
    "count = 0 \n",
    "for question in QUESTIONS:\n",
    "    count += 1\n",
    "    print(f\"❓Ask {count}: -> {question}\")\n",
    "    user_message,command = set_user_message(prompt=question)\n",
    "    chat_request_details = set_chat_params(command=command,user_message=user_message,mode=\"set\")\n",
    "    oci_genai_chat_details = set_oci_genai_chat_details(model_id=MODEL_ID,compartment_id=COMPARTMENT_ID,chat_request_details=chat_request_details)\n",
    "    chat_response_from_step1 = run_chat_using_oci_geneai(\n",
    "        oci_genai_chat_details=oci_genai_chat_details,\n",
    "        generative_ai_inference_client=generative_ai_inference_client,\n",
    "        message=\"❶ Step-1 set tool\"\n",
    "    )\n",
    "    tool_call_message,tool_message=parse_function_results_for_tool_executions(chat_response=chat_response_from_step1)\n",
    "    chat_request_details_for_tool_run = set_chat_params(command=command,user_message=user_message,mode=\"run\",\n",
    "                                                        tool_call_message=tool_call_message,tool_message=tool_message)\n",
    "    oci_genai_chat_details.chat_request = chat_request_details_for_tool_run\n",
    "    chat_response_from_step2 = run_chat_using_oci_geneai(\n",
    "        oci_genai_chat_details=oci_genai_chat_details,\n",
    "        generative_ai_inference_client=generative_ai_inference_client,\n",
    "        message=\"❷ Step-2 run tool\",\n",
    "        verbose=True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
